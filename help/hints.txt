- Before using etl.sh, Start 2 instances of elasticsearch. (Remember to pass the 2nd instance a path for data and logs, see https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started-install.html)


# index it:
# curl -H "Content-Type: application/json" -XPOST "localhost:9200/papers/_bulk?pretty&refresh" --data-binary "@paper.json"

# search for it;
"""
curl -X GET "localhost:9200/papers/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "query": { "match_phrase": { "body_text": "interleaved" } }
}
'
"""

# check status:
# curl "localhost:9200/_cat/indices?v"

# delete index:
# curl -X DELETE "localhost:9200/[index name]?pretty"


(OUTDATED!) original repository/data readme:

1. Download dataset https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge to this folder.
It will have several directories mentioned in 'parse_paper_jsons.py' filled with papers. 
This data is omitted from this commit/repo for space.

2. Run 'parse_paper_jsons.py' - this creates the trimmed_papers directory with all papers with trimmed fields
in it, all as their own .json file.

3. Start at least 2 instances of elasticsearch. For the 2nd instance, specify a data path and log path:
https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started-install.html

4. Run 'indexer.go' to bulk index batches of the documents from trimmed_papers at a time.

(Done)


N2. 'paper_single.json' is a single paper formatted to be ready for bulk indexing via curl, for testing only.

-----------------
BERT:
pip install ... 
tensorflow==1.15.2 (tf2 forces you to have to upgrade the python files with tf2_upgrade_v2)
bert-serving-server
bert-serving-client 

then run 
bert-serving-start -model_dir cased_L-12_H-768_A-12/ -num_worker=1
where 'cased_L...' is where the bert model is saved (from https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip)
*note: num_worker controls the number of allowed concurrent requests 

-----------------
bert encoding implemented in etl_transform.py , 
but you have to run bert-serving-server process first!
bert-serving-start -num_worker=1 -model_dir cased_L-12_H-768_A-12/ -num_worker=1 -max_seq_len=NONE
(not setting last option defaults max seq len to 25 which can make embeddings less accurate)
